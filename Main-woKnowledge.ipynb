{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    " \n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True  \n",
    "session = tf.Session(config=config)\n",
    " \n",
    "KTF.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypers import *\n",
    "from preprocess import *\n",
    "from Knowledge import *\n",
    "from Models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_path='/data1/qitao/BERT/chinese_L-12_H-768_A-12/'\n",
    "emb_root_path = '/data/data/qit/cnchar.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_word_index_path=bert_path+'vocab.txt'\n",
    "\n",
    "bert_config_path = os.path.join(bert_path,'bert_config.json')\n",
    "bert_checkpoint_path = os.path.join(bert_path,'bert_model.ckpt')\n",
    "bert_vocab_path = os.path.join(bert_path,'vocab.txt')\n",
    "\n",
    "bert_voca = read_bert_word_index(bert_word_index_path)\n",
    "\n",
    "bert = keras_bert.load_trained_model_from_checkpoint(bert_config_path,\n",
    "                                                        bert_checkpoint_path, \n",
    "                                                        training=False,\n",
    "                                                        trainable=True,\n",
    "                                                        seq_len=max_text_length,\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData,TestData,Centorid = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dict = {}\n",
    "tp_dict = {}\n",
    "    \n",
    "train_input, train_label, train_mask = parse_datav2(TrainData,char_dict,tp_dict,bert_voca)\n",
    "test_input, test_label, test_mask = parse_datav2(TestData,char_dict,tp_dict,bert_voca)\n",
    "train_mask = train_mask.reshape((train_mask.shape[0],max_entity_num*max_entity_num,))\n",
    "train_label = train_label.reshape((train_label.shape[0],max_entity_num*max_entity_num,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix=Init_char_embedding(emb_root_path,char_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "242/242 [==============================] - 343s 1s/step - loss: 0.1331\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 323s 1s/step - loss: 0.0654\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 318s 1s/step - loss: 0.0340\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 317s 1s/step - loss: 0.0172\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 315s 1s/step - loss: 0.0101\n",
      "test (0.9887448294675105, 0.6330081000890088, 0.9576660630890312, 0.762205597033837)\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 321s 1s/step - loss: 0.0069\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 317s 1s/step - loss: 0.0044\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 315s 1s/step - loss: 0.0047\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 312s 1s/step - loss: 0.0035\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 304s 1s/step - loss: 0.0023\n",
      "test (0.9910136997799327, 0.8111192930033947, 0.8651089730154026, 0.8372446555023993)\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 314s 1s/step - loss: 0.0019\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 312s 1s/step - loss: 0.0019\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 306s 1s/step - loss: 0.0017\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 305s 1s/step - loss: 0.0023\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 309s 1s/step - loss: 0.0010\n",
      "test (0.9923146936238186, 0.8174705448437527, 0.9036426535507078, 0.8583993813204717)\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 311s 1s/step - loss: 9.7134e-04\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 307s 1s/step - loss: 0.0012\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 334s 1s/step - loss: 0.0014\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 344s 1s/step - loss: 0.0012\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 347s 1s/step - loss: 0.0012\n",
      "test (0.9909376336076087, 0.6913659793178051, 0.9866018651009323, 0.8130107700586663)\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 324s 1s/step - loss: 0.0016\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 323s 1s/step - loss: 7.3397e-04\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 333s 1s/step - loss: 6.0529e-04\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 337s 1s/step - loss: 4.7292e-04\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 340s 1s/step - loss: 4.9857e-04\n",
      "test (0.9940537237014324, 0.9068483062493696, 0.8870081929515613, 0.8968185334398235)\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 325s 1s/step - loss: 4.4504e-04\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 327s 1s/step - loss: 7.5842e-04\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 343s 1s/step - loss: 6.3429e-04\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 339s 1s/step - loss: 4.3596e-04\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 338s 1s/step - loss: 4.4959e-04\n",
      "test (0.9938071643842443, 0.796391752504014, 0.9830701055581104, 0.8799389777899883)\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 330s 1s/step - loss: 4.9536e-04\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 325s 1s/step - loss: 0.0028\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 333s 1s/step - loss: 0.0012\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 325s 1s/step - loss: 5.8565e-04\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 322s 1s/step - loss: 4.3990e-04\n",
      "test (0.9939933953578651, 0.811303387259637, 0.9734923789514587, 0.8850286172421902)\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 318s 1s/step - loss: 3.2210e-04\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 320s 1s/step - loss: 2.5435e-04\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 303s 1s/step - loss: 2.7873e-04\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 292s 1s/step - loss: 2.8759e-04\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 292s 1s/step - loss: 2.9065e-04\n",
      "test (0.9939881494149462, 0.9036266567651301, 0.8874525401475816, 0.8954665692880173)\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 293s 1s/step - loss: 2.1712e-04\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 330s 1s/step - loss: 1.8939e-04\n",
      "Epoch 3/5\n",
      "242/242 [==============================] - 316s 1s/step - loss: 2.3400e-04\n",
      "Epoch 4/5\n",
      "242/242 [==============================] - 314s 1s/step - loss: 4.4449e-04\n",
      "Epoch 5/5\n",
      "242/242 [==============================] - 311s 1s/step - loss: 3.4184e-04\n",
      "test (0.9948878286255367, 0.8518961707610552, 0.9645648774398577, 0.9047363017835929)\n",
      "Epoch 1/5\n",
      "242/242 [==============================] - 290s 1s/step - loss: 2.0550e-04\n",
      "Epoch 2/5\n",
      "242/242 [==============================] - 294s 1s/step - loss: 1.8999e-04\n",
      "Epoch 3/5\n",
      "104/242 [===========>..................] - ETA: 2:44 - loss: 2.6985e-04"
     ]
    }
   ],
   "source": [
    "use_bert = True\n",
    "char_cnn = True\n",
    "char_lstm = True\n",
    "entity_type = True\n",
    "entity_cnn = True\n",
    "entity_lstm = True\n",
    "\n",
    "model = get_modelv2(emb_matrix,bert,tp_dict,use_bert,char_cnn,char_lstm,entity_type,entity_cnn,entity_lstm)\n",
    "model.compile(Adam(0.0001),loss='binary_crossentropy',sample_weight_mode=\"temporal\")\n",
    "\n",
    "for i in range(25):\n",
    "    model.fit(train_input,train_label,epochs = 5,batch_size=2,sample_weight=train_mask)\n",
    "    pred = infer(model,test_input,test_mask)\n",
    "    g = evaluation(pred,test_label,test_mask)\n",
    "    print('test',g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(ds)",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
